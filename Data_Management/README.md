## Data Management Scripts
`cleanup_sample.sh` deletes all bam files of a sample except for the final passing bam file. 
Also removes the temporary files generated by the QC scripts

`push_sample_s3.sh` was made to push a germline project to amazon s3 storage. 
It finds the completed samples, and the pushes them using `push_files_s3.sh`

`push_files_s3.sh` pushes any file(s) to amazon s3 storage. 
The amazon [AWS Command Line Interface](http://docs.aws.amazon.com/cli/latest/userguide/cli-chap-welcome.html)
uploads the files for you. Here are the steps I ran to set it up:

	sudo pip install awscli
	sudo pip install --upgrade awscli
	aws configure
		AWS Access Key ID [None]: AKIIOSFONN7EXAMPLE
		AWS Secret Access Key [None]: wJalrXUtnEMI/KMEG/bPxRiCYEXAMPLEKEY
		Default region name [None]: us-west-2
		Default output format [None]: json

`open_einstein.py` is a small script I made to open all of the samples I pushed to s3 so I could check to make sure
they all pushed correctly. I also ran the bash command below to check to make sure the BAM file I pushed was the same 
size as the BAM file that's on s3. It seems like s3 always rounds the size down to the nearest GB.

	for bam in `find /path/to/project -name "*.bam"`; do du -sh $bam; done

